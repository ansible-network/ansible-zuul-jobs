---

###
# Code lint, smell, compile test
# See: http://docs.ansible.com/ansible/devel/dev_guide/testing_sanity.html
#      http://docs.ansible.com/ansible/devel/dev_guide/testing/sanity/

###
# To test this Ansible Role using ansible-test we:
# 1) Create results directory structure, which in the future can be used for ansibullbot
# 2) Copy everything into "{{ ansible_path }}/role-to-test"
# 3) Move modules, action plugins etc into the correct location under "{{ ansible_path }}/lib/ansible/" so they get tested correctly
#    For this we just use shell mv. with_fileglob doesn't support running on remote-node
#    As we are running only once we don't care about this being idempotent
# The above steps are only needed till ansible-test is updated to know about galaxy file structure and test $CWD, rather than an Ansible checkout

###
# Setup results structure
#

# Ensure we have clean results structure to store results files
# This could be used in the future to enable ansibullbot
- name: Ensure previous results files have been removed
  file:
    path: "{{ ansible_path }}/test/results/bot"
    state: absent

- name: Create results directory
  file:
    path: "{{ ansible_path }}/test/results/bot"
    state: directory

- name: Create sub results file
  copy:
    content: '{"verified": false, "results": []}'
    dest: "{{ ansible_path }}/test/results/bot/ansible-test-failure.json"

##
# TEMPORARY: START
#
- name: Create directory structure under Ansible checkout
  file:
    path: "{{ ansible_user_dir }}/{{ ansible_path }}/{{ item.path }}"
    state: "{{ item.state|default('directory') }}"
  with_items:
    - { path: "lib/ansible/modules/galaxy/" }
    - { path: "lib/ansible/modules/galaxy/__init__.py", state: touch }
    - { path: "lib/ansible/module_utils/galaxy/" }
    - { path: "lib/ansible/module_utils/galaxy/__init__.py", state: touch }
    - { path: "lib/ansible/plugins/from_galaxy/" }
    - { path: "lib/ansible/plugins/from_galaxy/__init__.py", state: touch }

- name: Symlink role into ansible/role-to-test
  shell: "ln -s {{ ansible_user_dir }}/{{ zuul.project.src_dir }} {{ ansible_user_dir }}/{{ ansible_path }}/role-to-test"

- name: Move certain files to know locations so correct tests are run
  shell: "mv {{ ansible_path }}/role-to-test//{{ item.src }} {{ ansible_path }}/{{ item.dest }}"
  with_items:
    - { src: "action_plugins/*", dest: "/lib/ansible/plugins/action/"}
    - { src: "library/*", dest: "/lib/ansible/modules/galaxy/"}
    - { src: "lib/*/plugins/*", dest: "/lib/ansible/plugins/from_galaxy/"}
    - { src: "lib/*", dest: "/lib/ansible/module_utils/galaxy/"} # FIXME maybe rename this?
  ignore_errors: yes

###
# Run ansible-test
#

- name: Build test options
  set_fact:
    standard_options: '--color no --tox --failure-ok --junit'
    skip_options: '--skip-test azure-requirements --skip-test configure-remoting-ps1 --skip-test integration-aliases --skip-test required-and-default-attributes --skip-test sanity-docs --skip-test test-constraints --skip-test docs-build --skip-test rstcheck'
    test_targets: "{{ ansible_user_dir }}/{{ zuul.project.src_dir }}"

# Firstly, run all the tests (exec skip_options) against Python 3.x
- name: Run ansible-test against Python 3.6
  command: "{{ ansible_path }}/test/runner/ansible-test sanity --python 3.6 {{ standard_options }} {{ skip_options }} {{ test_targets }}"

# NOTE(pabelanger): Skip python2.6 here, since this is fedora-28.
# Secondly, run each of the SanityMultipleVersion tests against the remaining available Python versions
- name: Run ansible-test for SanityMultipleVersion
  command: "{{ ansible_path }}/test/runner/ansible-test sanity --python {{ item }} {{ standard_options }} --test ansible-doc --test compile --test import {{ test_targets }}"
  with_items:
    - "2.7"
    - "3.6"

##
# Check for failures
#

- name: Remove temporary results file
  file:
    path: "{{ ansible_path }}/test/results/bot/ansible-test-failure.json"
    state: absent

- name: Examine results files
  find:
    path: "{{ ansible_path }}/test/results/bot"
    patterns: "ansible-test-*.json"
  register: results_files

- name: Check for failing tests
  fail:
    msg: One or more tests have failed
  when:
    results_files.matched

# FIXME FUTURE copy test/sanity bot meta else where so ansibullbot can source them?
# FIXME FUTURE Python 3.7 support
